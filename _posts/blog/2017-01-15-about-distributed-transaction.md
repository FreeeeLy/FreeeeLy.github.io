---
layout: post
title: 关于分布式事务的一些小结
description: some note about distributed transaction
category: blog
---

## 关于分布式事务 ##
接触分布式系统也有一段时间了，其中很大一块的内容就是分布式事务，分布式事务概念很多，既然是小结就无须长篇大论的抄袭一些网上到处都有的名词介绍了。分布式事务最终的目的都是为了解决数据的一致性问题，何谓数据一致性，简单的理解就是我在某个时刻期望获取到的数据就是我最近一次成功修改的数据.

## 为什么出现了分布式事务 ##
一门技术的出现肯定是为了解决现实问题的，想想我们业务中最容易遇到问题：

1. 服务器性能不足以支撑我们的业务量了，我们想增加一些机器
2. 机器总有故障的时候，但是当机器故障的时候我们却不想影响我们的业务(比如业务中断，数据丢失等等)

聪明的工程师想了很多方法去做到以上两点，主要的解决方法大都是围绕着:

1. 数据冗余，即多副本存储机制来降低单点故障的影响
2. 分区存储数据，按照数据的某维特征把数据分布具体的服务器节点，最常见的如一致性哈希

当我们做数据冗余的时候，我们就要写多份数据，写多份数据我们不得不又面临一个新的挑战，我们如何保证多份数据之间的一致性，因此就出现了分布式事务，来解决分布式系统下数据一致性的问题

这就是我们的工程师的日常，仿佛解决了一个问题之后，又不得不去面对一个新的问题。

## 数据的一致性模型 ##

关于数据一致性模型细分有很多，但是主要有如下几种分类:

1. 强一致性：在每次更新之后，后续的操作一定会读到最新的值，最常见的例子就如RDBMS和文件系统
2. 弱一致性：在每次更新之后不一定保证能够读取到最新的值，需要满足一定的条件之后才能够读取到最新的值，即有一段不一致的时间窗
3. 最终一致性：属于弱一致性的一个分支，在更新某个数据之后，在经过一段时间后，每次操作都会返回最新的数据

强一致性是更加传统，符合人们使用习惯的一种模型，方便易用，能满足大部分场合的要求。像弱一致性，最终一致性，更多的是一种无奈之举，在高并发，大数据量下的权衡之计

## 实现数据一致性的技术 ##

### 主从Master-Slave结构 ###

在这种结构中，读写操作都由Master来处理，然后Master把数据同步给Slave

从Master到Slave之间的数据同步可以是异步的，也可以是同步的。如果是使用异步的方式进行数据同步，实际上就是相当于最终一致性了，在数据写入Master但未异步同步成功这个时间窗中，数据是不一致的。使用异步方式同步还有个好处就是可以避免因为Slave的down机而导致服务中断，由于异步的，可以暂缓数据的同步（如果对灾备没有严格的要求的话）

使用同步方式进行数据复制的话可能需要考虑几点：

1. 能否容忍Slave挂掉导致Master终止服务
2. Master或者Slave在数据同步失败时候的回滚，数据修正操作

### 主主Master-Master结构 ###

Master-Master跟Master-Slave主要的区别就是，Master-Master中每台服务器都可以处理读写操作，然后Master之间通过异步的方式进行数据同步，这同样有个时间窗的问题，所以也是最终一致性的一种。

## 2PC(Two Phase Commit) ###

中文简称2阶段提交，即在一次完整的事务中加入一个协调者的角色，来主导整个事务的进行。整个事务分成两个阶段：

1. 阶段一：事务请求阶段

    在这个阶段中，协调者向这次事务操作的参与者发送一个是否可以执行某个事务的请求，参与者在接收到协调者的请求之后，锁定资源进行相应的操作，但并不提交，记录redo和undo日志，并且向协调者返回Yes或者No来表示是否可以继续进行事务的提交

1. 阶段二：事务提交阶段

    如果所有的参与者都返回Yes，那么协调者会向所有的参与者发送COMMIT请求，这时候所有参与者会完成提交并且释放资源，如果有参与者返回No，那么协调者会发送一个RollBack的请求，进行事务的回滚

在2PC这个方案之中主要会有以下几个缺点：

- 单点失效的问题，尤其当协调者挂掉之后，可能会导致全局的某个资源被锁定，试想在阶段一已经完成但尚未进行阶段二这个时间窗内协调者一旦挂了，那么所有参与者锁定的资源将无法得到释放

- 会出现数据不一致的情况，由于节点间的通信是通过消息来传递的，一旦消息丢失，那么数据就很容易不一致:

   1. 当所有参与者都表示Yes，接受该事务的时候，协调者发送给某个参与者的Commit消息在途中丢失了，这个时候参与者无法得知下一步如何处理，一直锁定资源，直到人工去干预这一次事务
   2. 当所有参与者都表示Yes，接受该事务的时候，协调者与某个参与者同时挂掉了，这个时候如果选举一个新的协调者继续这次事务，新的协调者只能够重新的去询问一次所有的参与者，才能继续进行commit操作，但是有个问题就是，新的协调者无法得知挂掉的那个参与者进行了什么操作，导致事务无法继续进行.

- 整个2PC是基于同步阻塞来实现的，性能问题堪忧

虽然可以通过加入超时机制来改善一下上述的缺点，但要在2PC上设计一个完备的容错机制很难。

## 3PC(Three Phase Commit) ##

3PC在2PC的基础上多增加一个preCommit的阶段，可以有效解决2PC中当协调者与参与者同时挂掉之后，无法追溯状态的问题：

1. 阶段一：CanCommit

    协调者询问参与者是否可以进行某个事务操作，并且等待参与者回应，这个阶段参与者不会进行具体的事务操作，只会进行应答

2. 阶段二：PreCommit

    和2PC的阶段一类似

3. 阶段三：doCommit

    和2PC的阶段二类似

3PC看起来和2PC差不多，如果不仔细思考可能会觉得会和2PC一样会出现协调者与参与者同时挂掉之后，无法追溯状态的问题，但是其中当中是截然不同的：

假设网络没有分区，即所有消息都能顺利到达的前提下:在2PC中，假如我们在协调者和参与者同时挂掉之后，再推举一台新的协调者出来，新的协调者根本不会知道挂掉的那台参与者应该进行什么操作，导致事务无法进行下去。在3PC中，新的协调者可以通过询问未挂掉的机器的状态，如果未挂掉的机器中有处于doCommit状态的机器，那么我们可以知道挂掉的那台机器一定是同意了这次COMMIT的，因为只有所有的机器都同意了，才会进行第三阶段，所以我们可以对挂掉的进行也发送一个COMMIT请求,否则可以回滚这次事务

3PC解决了的问题:

1. 降低了单点故障对全局的影响，如果节点故障发生在CanCommit阶段，这个时候所有参与者都没有锁定任何资源，只需要简单的放弃本次事务即可.
2. 如果单点故障发生在PreCommit或者doCommit阶段，可以通过存活的参与者节点的状态判断事务该如何继续进行下去，这是与2PC不同的地方
3. 3PC可以通过加入超时机制，来进行故障时的超时提交/回滚，降低阻塞带来的全局影响

但是3PC并没有解决网络分区的问题，如果进入preCommit阶段之后，网络出现分析，仍然会出现部分提交，部分回滚从而数据不一致的问题


## Paxos算法 ##

Google Chubby的作者Mike Burrows说过：
	
> there is only one consensus protocol, and that’s Paxos” – all other approaches are just broken versions of Paxos.

Paxos能得到如此美誉，和其精妙算法密切相关，我看了很多Paxos的相关资料，也就是只能够勉强理解一些Paxos的精髓，这里就不班门弄斧了，关于Paxos可以移步以下文章，对Paxos进行了解:

[如何浅显易懂地解说 Paxos 的算法？](https://www.zhihu.com/question/19787937 "如何浅显易懂地解说 Paxos 的算法？")

[Wiki百科关于Paxos的解释](https://en.wikipedia.org/wiki/Paxos_(computer_science) "https://en.wikipedia.org/wiki/Paxos_(computer_science)")

[Lamport的论文](http://lamport.azurewebsites.net/pubs/paxos-simple.pdf "http://lamport.azurewebsites.net/pubs/paxos-simple.pdf")

## Raft算法 ##

Paxos固然优美，但是晦涩难以理解以及工程上实现的坑点，人们实现了Raft算法，Raft更加容易让人理解以及更注重工程的实现性。但是Raft算法本人还没进行深入的了解，这里先挖个坑。日后再补.

[Raft论文](https://raft.github.io/raft.pdf "https://raft.github.io/raft.pdf")